#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Oct 22 15:21:41 2019

@author: marleezinsser
"""

import csv
import pandas as pd

import API_Wrapper

#Note, in my version of the API_Wrapper, the date range for search is set to 2010 to 2018.
#This is intended to reduce the number of results we get.


df0 = get_annotations(0,1, 'heart failure', True, 'PubTator')
df1 = get_annotations(1,100, 'heart failure', True, 'PubTator')
df2 = get_annotations (100,200, 'heart failure', True, 'PubTator')
df3 = get_annotations (200, 300, 'heart failure', True, 'PubTator')



df4 = get_annotations(300,400, 'heart failure', True, 'PubTator')
df5 = get_annotations(400,500, 'heart failure', True, 'PubTator')
df6 = get_annotations(500,600, 'heart failure', True, 'PubTator')
df7 = get_annotations(600,700, 'heart failure', True, 'PubTator')

df8 = get_annotations(700,800, 'heart failure', True, 'PubTator')


df9 = get_annotations(800,900, 'heart failure', True, 'PubTator')

df10 = get_annotations(900,1000, 'heart failure', True, 'PubTator')

df11 = get_annotations(1000,1010, 'heart failure', True, 'PubTator')


#^in total we stop after searching for 101,490 PMIDs
#Note: We produce a df of over 400,000 rows, because a row is generated for each unique PMID-MESH pair.


big_df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11])

agg_df = aggregate_results(big_df)




agg_df.to_csv('/Users/marleezinsser/opt/anaconda3/lib/python3.7/site-packages/neo4j/import/PMID-MESH-DISEASE.csv')
