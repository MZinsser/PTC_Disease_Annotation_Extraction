#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Mar 12 14:19:53 2020
@author: marleezinsser
"""
from bs4 import BeautifulSoup
from nltk.stem.snowball import SnowballStemmer

import csv


import pandas as pd
import requests
import nltk
#INPUT FILES
#arrhythmia_input_file = '/Users/marleezinsser/Desktop/arrhythmia_PMID_matches.csv'
#heart_failure_input_file = '/Users/marleezinsser/Desktop/heart-failure-similar-diseases.csv'
#coronary_artery_disease_input_file = '/Users/marleezinsser/Desktop/coronary-artery-disease-similar-diseases.csv'
hfpef_input_file= '/Users/marleezinsser/Desktop/hfpef_pmid_candidates.csv'


#Aggregate multiple matches for the same PMID by summing the scores and concatenating
#the entities
hfpef_raw = pd.read_csv(hfpef_input_file)
agg_functions = {'SCORE':'sum', 'related_entity':', '.join}
summarized_hfpef = hfpef_raw.groupby(['PMID']).aggregate(agg_functions)
summarized_hfpef = summarized_hfpef.sort_values(by = ['SCORE'], ascending = 'False')


#Define some functions for processing the matched PMID candidates:

def parse_pmid_match_results (inputfile):

    df = pd.read_csv(inputfile)


    possible_PMIDs= df['PMID']

    df_new = pd.DataFrame(columns = ['possible_PMIDs'])
    df_new['possible_PMIDs']=possible_PMIDs
    df_new.drop_duplicates()
    return df_new




match_success_list = []


def evaluate_PMID_matches(df):
    
    main_df = pd.DataFrame()
    
#    strings = [str(integer) for integer in integers]
#a_string = "".join(strings)
    
    id_list = hfpef_matched_PMIDs['possible_PMIDs'].tolist()
    id_strings = [str(integer) for integer in id_list]
    
   # url = "https://www.ncbi.nlm.nih.gov/research/pubtator-api/publications/export/pubtator?pmids=" + ids + "&concepts=disease"

    match_list = []
    preserved = []
    x=0;
    while(x<50):
#    for x in range (0, 200):
    #for x in range (0, len(id_strings)):
    
        
    
       # smaller_id_list = id_strings[x:x+100]
       # ids = ','.join(smaller_id_list)
        #print ("getting articles for: ")
       # print (len(smaller_id_list)," ids")
       curr_id = id_list[x]
       curr_id = str(curr_id)
       print("searching for hfpef in PMID", x)
       url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id=" + curr_id + "&retmode=text&rettype=abstract"
       response = requests.get(url)
       from io import StringIO
       ptf_str = response.text
        #ptf_str = StringIO(ptf_str)
       # columns = ['PMID', 'Delete1', 'Delete2', 'Disease','Delete3', 'MESH']
        #df = pd.DataFrame(columns = columns)
            #df = pd.read_csv('output.csv', delimiter = '\t',names = columns)
        
    
        
       # main_df = main_df.append(df)
       
       print(ptf_str)
       #stemmer = SnowballStemmer("english")
       tokens = nltk.word_tokenize(ptf_str)
       for token in tokens:
           #stem = stemmer.stem(token)
          # if(stem == "hfpef")
           if (token == "hfpef"):
               print ("match found in doc")
               match_list.append(curr_id)
           if (token == "hf-pef"):
               print ("match found in doc")
               match_list.append(curr_id)
           if (token == "preserved"):
               print ("match found in doc")
               match_list.append(curr_id)
               preserved.append(curr_id)
             
               
           #else:
               #print ("no match")
       x= x+1
    
       # prin
    return match_list

hfpef_matched_PMIDs = parse_pmid_match_results(hfpef_input_file)



match_success_list = evaluate_PMID_matches(hfpef_matched_PMIDs)
match_list_no_dups = list(dict.fromkeys(match_success_list))




#match_list_no_dups.to_csv()
#ptf_str = get_PMID_contents(arrhythmia_matched_PMIDs)
        
#with open('listfile.txt', 'w') as filehandle:
   # for listitem in match_list_no_dups:
      #  filehandle.write('%s\n' % listitem)
    




